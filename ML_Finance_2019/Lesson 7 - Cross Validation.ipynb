{
  "cells": [
    {
      "metadata": {
        "heading_collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Cross Validation"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "* Hold out Cross Validation\n* k-fold Cross Validation"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. \n\nIn the basic approach, called k-fold CV, the training set is split into k smaller sets. The following procedure is followed for each of the k “folds”:\n* A model is trained using k-1 of the folds as training data;\n* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n\nThe performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. "
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "## Holdout Method"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "* Split initial dataset into a separate training and test dataset\n* Training dataset - model training\n* Test dataset - estimate its generalisation performance"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "![img](holdout_method.PNG)"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "## Holdout Method with Validation"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "A variation is to split the training set to two :- training set and validation set\n\nTraining set:- For fitting different models\n\nValidation set :- For tuning and comparing different parameter settings to further improve the performance for making predictions on unseen data. And finally for model selection.\n\nThis process is called model selection. We want to select the optimal values of tuning parameters (also called hyperparameters). \n"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "<img style=\"float: left;\" src=\"holdout_method_w_validation.png\" height=75%, width=75%>"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "## K-fold Cross-Validation"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "* Randomly split the training dataset into k folds without replacement.\n\n* k — 1 folds are used for the model training.\n\n* The one fold is used for performance evaluation. \n\nThis procedure is repeated k times. \n\nFinal outcomes:- k models and performance estimates.\n\n* calculate the average performance of the models based on the different, independent folds to obtain a performance estimate that is less sensitive to the sub-partitioning of the training data compared to the holdout method. \n\n* k-fold cross-validation is used for model tuning. Finding the optimal hyperparameter values that yields a satisfying generalization performance.\n\n* Once we have found satisfactory hyperparameter values, we can retrain the model on the complete training set and obtain a final performance estimate using the independent test set. The rationale behind fitting a model to the whole training dataset after k-fold cross-validation is that providing more training samples to a learning algorithm usually results in a more accurate and robust model.\n\n\n* Common k is 10\n\n* For relatively small training sets, increase the number of folds. "
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "<img style=\"float: left;\" src=\"cross_validation.png\" height=75%, width=75%>"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "## Stratified k-fold cross-validation\n"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "\n* variation of k-fold\n* Can yield better bias and variance estimates, especially in cases of unequal class proportions"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "## Illustration"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "### Cross-validation: evaluating estimator performance\n\nAdapted from [scikit learn](Cross-validation: evaluating estimator performance)"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "**overfitting**:\n* It is a mistake to expose your machine learning algorithm to both training and testing data\n* This will lead to overfitting\n* It will give a high score \n* Utterly useless for unseen data"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "**Note**:\n\n* Hyperparameters for estimators, such as the `C` for SVM, must be set manually\n* There is still a risk of overfitting on the test set because one can continually tweek the parameters\n* To avoid this, another part of the dataset should be held out as “validation set”\n    1. Training proceeds on the training set\n    2. Evaluation is done on the validation set\n    3. Final evaluation can be done on the test set."
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "* This raised another issues as we have drastically reduced the number of samples which can be used for learning the model\n* To get around this, we utilise a procedure called cross-validation (CV). \n* A test set should still be held out for final evaluation\n* The validation set is no longer needed when doing CV. \n* In k-fold CV, the training set is split into k smaller sets\n* The following procedure is followed for each of the k “folds”:\n    * A model is trained using k-1 of the folds as training data\n    * The resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n    * The performance measure reported by k-fold cross-validation is then the average of the values. \n* Can be computationally expensive\n* Does not waste too much data "
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "\n**Best Practice**:\n* Hold out part of the available data as a **test set** `X_test`, `y_test`. "
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "In **scikit-learn** a random split into training and test sets can be quickly computed with the `train_test_split` helper function. \n\n"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom sklearn import svm\n\nboston = datasets.load_boston()\nboston.data.shape, boston.target.shape",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "((506, 13), (506,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our regressor:"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, \n                                                    test_size=0.4, random_state=0)\nregression = svm.SVR(kernel='linear', C=1).fit(X_train, y_train)\nprint(regression.score(X_test, y_test))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.6672554157940424\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "### Computing cross-validated metrics"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "5 fold cross validation"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\nregression = svm.SVR(kernel='linear', C=1)\nscores = cross_val_score(regression, boston.data, boston.target, cv=5)\nscores        ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "array([0.77328953, 0.72833447, 0.53795481, 0.15209389, 0.07729196])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "The mean score and the 95% confidence interval of the score estimate are hence given by:"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 0.45 (+/- 0.58)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the scoring parameter:"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import metrics\nscores = cross_val_score(\n    regression, boston.data, boston.target, cv=5, scoring='neg_mean_squared_error')\nscores ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array([ -7.82949025, -24.73154773, -37.00390719, -74.37141515,\n       -24.53325372])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "See [The scoring parameter: defining model evaluation rules](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal."
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "When the `cv` argument is an integer, `cross_val_score` uses the `KFold` or `StratifiedKFold` strategies by default, the latter being used if the estimator derives from ClassifierMixin."
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "### K-fold"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "`KFold` divides all the samples in k groups of samples, called folds (if k = n, this is equivalent to the Leave One Out strategy), of equal sizes (if possible). \n\nThe prediction function is learned using k - 1 folds, and the fold left out is used for test.\n\nExample of 2-fold cross-validation on a dataset with 4 samples:"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.model_selection import KFold\n\nX = [\"a\", \"b\", \"c\", \"d\"]\nkf = KFold(n_splits=2)\nfor train, test in kf.split(X):\n    print(\"%s %s\" % (train, test))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[2 3] [0 1]\n[0 1] [2 3]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "### Stratified k-fold"
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "StratifiedKFold is a variation of k-fold which returns stratified folds\n\nEach set contains approximately the same percentage of samples of each target class as the complete set.\n\nExample of stratified 3-fold cross-validation on a dataset with 10 samples from two slightly unbalanced classes:"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import StratifiedKFold\n\nX = np.ones(10)\ny = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\nskf = StratifiedKFold(n_splits=3)\nfor train, test in skf.split(X, y):\n    print(\"%s %s\" % (train, test))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[2 3 6 7 8 9] [0 1 4 5]\n[0 1 3 4 5 8 9] [2 6 7]\n[0 1 2 4 5 6 7] [3 8 9]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Pipeline\n\nStandardScalar\n\nPCA\n\nSVM.SVR"
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n#from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.pipeline import make_pipeline\n#pipe_lr = make_pipeline(StandardScaler(),\n#                        PCA(n_components=2),\n#                        LogisticRegression(random_state=1))\npipe_svm = make_pipeline(StandardScaler(),\n                        PCA(n_components=2),\n                        svm.SVR(kernel='linear', C=1))\npipe_svm.fit(X_train, y_train)\ny_pred = pipe_svm.predict(X_test)\nprint('Test Accuracy: %.3f' % pipe_svm.score(X_test, y_test))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Test Accuracy: 0.391\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\nscores = cross_val_score(estimator=pipe_svm,\n                         X=X_train,\n                         y=y_train,\n                         cv=10,\n                         n_jobs=1)\nprint('CV accuracy scores: %s' % scores)\n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CV accuracy scores: [0.63971176 0.43579197 0.46977821 0.25027246 0.5124364  0.26221374\n 0.30877195 0.54528563 0.37810066 0.47313549]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),\n                                      np.std(scores)))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "CV accuracy: 0.428 +/- 0.121\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "hidden": true
      },
      "cell_type": "markdown",
      "source": "***"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
